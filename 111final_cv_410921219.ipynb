{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 480, 3)\n",
      "(19, 19, 3)\n",
      "min:0.17087361216545105 max:1.0\n",
      "min_n:-4.8918238348960585e-09 max_n:1.0\n",
      "result.min_max: (-4.8918238348960585e-09, 1.0, (89, 212), (109, 95))\n",
      "match_loc: (89, 212)\n",
      "right_bottom (108, 231)\n",
      "(270, 480, 3)\n",
      "min:0.17226606607437134 max:1.0\n",
      "min_n:-6.086608550504025e-09 max_n:1.0\n",
      "result.min_max: (-6.086608550504025e-09, 1.0, (89, 215), (108, 98))\n",
      "match_loc: (89, 215)\n",
      "right_bottom (108, 234)\n",
      "(270, 480, 3)\n",
      "min:0.1745903491973877 max:1.0\n",
      "min_n:1.0788596682687057e-09 max_n:1.0\n",
      "result.min_max: (1.0788596682687057e-09, 1.0, (88, 219), (108, 101))\n",
      "match_loc: (88, 219)\n",
      "right_bottom (107, 238)\n",
      "(270, 480, 3)\n",
      "min:0.18106190860271454 max:1.0\n",
      "min_n:5.58405766071246e-09 max_n:1.0\n",
      "result.min_max: (5.58405766071246e-09, 1.0, (88, 222), (108, 104))\n",
      "match_loc: (88, 222)\n",
      "right_bottom (107, 241)\n",
      "(270, 480, 3)\n",
      "min:0.17372898757457733 max:1.0\n",
      "min_n:4.512491713626332e-09 max_n:1.0\n",
      "result.min_max: (4.512491713626332e-09, 1.0, (86, 224), (108, 107))\n",
      "match_loc: (86, 224)\n",
      "right_bottom (105, 243)\n",
      "(270, 480, 3)\n",
      "min:0.1802438348531723 max:1.0\n",
      "min_n:-4.1752148405294065e-09 max_n:1.0\n",
      "result.min_max: (-4.1752148405294065e-09, 1.0, (112, 8), (108, 110))\n",
      "match_loc: (112, 8)\n",
      "right_bottom (131, 27)\n",
      "(270, 480, 3)\n",
      "min:0.17796902358531952 max:1.0\n",
      "min_n:-3.1117277643488706e-09 max_n:1.0\n",
      "result.min_max: (-3.1117277643488706e-09, 1.0, (96, 161), (108, 113))\n",
      "match_loc: (96, 161)\n",
      "right_bottom (115, 180)\n",
      "(270, 480, 3)\n",
      "min:0.1771876960992813 max:1.0\n",
      "min_n:-2.027654488756525e-09 max_n:0.9999999403953552\n",
      "result.min_max: (-2.027654488756525e-09, 0.9999999403953552, (95, 164), (108, 116))\n",
      "match_loc: (95, 164)\n",
      "right_bottom (114, 183)\n",
      "(270, 480, 3)\n"
     ]
    }
   ],
   "source": [
    "#game_1 : \"find_this_mii\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "scaling_factor = 1\n",
    "cap = cv2.VideoCapture(\"wiiplay.mp4\")\n",
    "frame_seq = 4820\n",
    "#####################\n",
    "#a\n",
    "#######################\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES , frame_seq);\n",
    "ret, img = cap.read()\n",
    "out_size = (480, 270)\n",
    "img = cv2.resize(img, out_size, 0, 0, interpolation=cv2.INTER_AREA)\n",
    "height, width = img.shape[0:2]\n",
    "print(img.shape)\n",
    "show_img = np.copy(img)\n",
    "mouse_pressed = False\n",
    "y0 = x0 = w = h = 0\n",
    "########################\n",
    "#b 自行手動抓取模板 選取後按'a'確定\n",
    "########################\n",
    "def mouse_callback(event, _x, _y, flags, param):\n",
    "    global show_img, x0, y0, w, h, mouse_pressed\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        mouse_pressed = True\n",
    "        x0, y0 = _x, _y\n",
    "        show_img = np.copy(img)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if mouse_pressed:\n",
    "            show_img = np.copy(img)\n",
    "            cv2.rectangle(show_img, (x0, y0), (_x, _y), (0, 255, 0), 2)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        mouse_pressed = False\n",
    "        w, h = _x - x0, _y - y0\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image', mouse_callback)\n",
    "\n",
    "#Acquire a template through mouse dragging\n",
    "while True:\n",
    "    cv2.imshow('image', show_img)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('a') and not mouse_pressed:\n",
    "        if w*h > 0:\n",
    "            break\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "template = np.copy(img[y0:y0+h, x0:x0+w])\n",
    "print(template.shape)\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR','cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "show_img = np.copy(img)\n",
    "\n",
    "cv2.imshow('image', template)\n",
    "###################################\n",
    "while True:\n",
    "    frame_seq += 1\n",
    "    if frame_seq > 5000:\n",
    "        frame_seq = 4820\n",
    "    if frame_seq < 4880:\n",
    "        frame_seq = 4880\n",
    "    \n",
    "    \n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES , frame_seq)\n",
    "    status_cap, img = cap.read()\n",
    "    if not status_cap:\n",
    "        break\n",
    "    img = cv2.resize(img, out_size, 0, 0, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k > 0 and chr(k).isdigit():\n",
    "        index = int(chr(k))\n",
    "        if 0 <= index < len(methods):\n",
    "            method = methods[index]\n",
    "            res = cv2.matchTemplate(img, template, eval(method))\n",
    "            print('min:{} max:{}'.format(np.min(res), np.max(res)))\n",
    "            res = cv2.normalize(res, None, 0, 1, cv2.NORM_MINMAX)            \n",
    "            print('min_n:{} max_n:{}'.format(np.min(res), np.max(res)))\n",
    "            #######\n",
    "            min_max = cv2.minMaxLoc(res)\n",
    "            if index == 4 or index == 5:   #根据不同的模式最佳匹配位置取值方法不同\n",
    "                match_loc = min_max[2]\n",
    "            else:\n",
    "                match_loc = min_max[3]  \n",
    "            right_bottom = (match_loc[0] + template.shape[1], match_loc[1] + template.shape[0])\n",
    "            print('result.min_max:',min_max)\n",
    "            print('match_loc:',match_loc)\n",
    "            print('right_bottom',right_bottom)\n",
    "            ########\n",
    "            # min_max = cv2.minMaxLoc(res)\n",
    "            #\n",
    "            #if index >= methods.index('cv2.TM_SQDIFF'):\n",
    "            #    loc = np.where(res < 0.2)\n",
    "            #else:\n",
    "            #    loc = np.where(res > 0.8)            \n",
    "            #for pt in zip(*loc[::-1]):\n",
    "            #    cv2.rectangle(res, (pt[0] - int(w/2), pt[1] - int(h/2)), (pt[0] + int(w/2), pt[1] + int(h/2)),(0, 0, 0), 1)\n",
    "            res_img = np.copy(res)\n",
    "            res_img = cv2.cvtColor(res_img, cv2.COLOR_GRAY2BGR)\n",
    "            for y in range(0, res.shape[0]):\n",
    "                for x in range(0, res.shape[1]):\n",
    "                    if (index >= methods.index('cv2.TM_SQDIFF')) and (res[y,x] < 0.2):            \n",
    "                        cv2.rectangle(res_img, (x - int(w/2), y - int(h/2)), (x + int(w/2), y + int(h/2)),(255, 0, 0), 1)\n",
    "                    elif (index < methods.index('cv2.TM_SQDIFF')) and (res[y,x] > 0.8):            \n",
    "                        cv2.rectangle(res_img, (x - int(w/2), y - int(h/2)), (x + int(w/2), y + int(h/2)),(255, 0, 0), 1)\n",
    "            #######     \n",
    "            #######\n",
    "            #print(res_img.shape)\n",
    "            res_img = cv2.resize(res_img, (width, height))*255\n",
    "            res_img = res_img.astype(np.uint8)\n",
    "            #print(res_img.shape)\n",
    "            cv2.putText(res_img, method, (0, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                \n",
    "            cv2.rectangle(res_img, match_loc,right_bottom, (0,0,255), 5, 8, 0 ) \n",
    "            show_img = np.copy(img)\n",
    "            show_img = cv2.resize(show_img, (width, height))\n",
    "            print(show_img.shape)\n",
    "            cv2.rectangle(show_img, match_loc,right_bottom, (0,0,255), 5, 8, 0 ) \n",
    "\n",
    "            show_img = np.hstack((show_img, res_img)) \n",
    "    ###\n",
    "    cv2.imshow(\"now_img\", img)\n",
    "    cv2.imshow('find_this_mii', show_img)\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) 一開始需要自行手動抓取模板 選取後按'a'確定  \n",
    "要看到效果需要持續的案0-5，通過0-5來選取需要的方法分別是  \n",
    "['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR','cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']  \n",
    "六種方法  \n",
    "c)找到跟模板最像的臉以後就用紅框框起來  \n",
    "\n",
    "  \n",
    "\n",
    "原本不用minMaxLoc()的方法時，經過測試'cv2.TM_CCOEFF'的效果比較好  \n",
    "不會找到太多奇怪的特徵，抓到的特徵比較少，但可以比較清楚的看到有抓到(藍色框框)  \n",
    "使用minMaxLoc()時，只有在方法'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED'有較好的效果(紅色框框)  \n",
    "多數的情況可以找到對的特徵點，'cv2.TM_SQDIFF'表現又比較好一點點  \n",
    "看起來要使用這兩個方法時，是一定要用到minMaxLoc()，不然基本看不出效果來  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game_2 : \"find_two_look_alike\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "scaling_factor = 1\n",
    "cap = cv2.VideoCapture(\"wiiplay.mp4\")\n",
    "start_seq = 2180\n",
    "frame_seq = start_seq\n",
    "\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES , frame_seq)\n",
    "status_cap, frame = cap.read()\n",
    "\n",
    "###\n",
    "#找路人\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "height, width =frame.shape[0:2]\n",
    "locations, weights = hog.detectMultiScale(frame, hitThreshold = 0.15, winStride=(1,1), groupThreshold = 1)\n",
    "\n",
    "\n",
    "while True:\n",
    "    frame_seq += 1\n",
    "    if frame_seq > 2380:\n",
    "        frame_seq = start_seq\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES , frame_seq)\n",
    "    status_cap, frame = cap.read()\n",
    "    if not status_cap:\n",
    "        break\n",
    "        \n",
    "    frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor)\n",
    "    \n",
    "    #負責找所有的臉\n",
    "    face_rects = face_cascade.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=2)\n",
    "    #負責找所有路人\n",
    "    locations, _ = hog.detectMultiScale(frame)\n",
    "    frame_out = np.copy(frame)\n",
    "    for (x,y,w,h) in face_rects:\n",
    "        cv2.rectangle(frame_out, (x,y), (x+w,y+h), (255,0,0), 3)\n",
    "\n",
    "    ####\n",
    "    #\n",
    "    if len(face_rects) >= 2:\n",
    "        for (x0, y0, w0, h0) in face_rects:\n",
    "            for (x1, y1, w1, h1) in face_rects:\n",
    "                #if x0 == x1 and y0 == y1 and w0 == w1 and h0 == h1:\n",
    "                face0 = frame[y0+int(h0/4):y0+int(h0*3/4), x0+int(w0/4):x0+int(w0*3/4)]\n",
    "                face1 = frame[y1+int(h1/4):y1+int(h1*3/4), x1+int(w1/4):x1+int(w1*3/4)]\n",
    "                gray0 = cv2.cvtColor(face0, cv2.COLOR_BGR2GRAY)\n",
    "                gray1 = cv2.cvtColor(face1, cv2.COLOR_BGR2GRAY)\n",
    "                wt,ht = face0.shape[0:2]\n",
    "                gray1 = cv2.resize(gray1, (wt,ht))\n",
    "                #計算相似程度\n",
    "                diff = cv2.absdiff(gray0, gray1)\n",
    "                #print(\"diff= \" + str(cv2.mean(diff)[0]))\n",
    "                #很像時，用紅色框起來\n",
    "                if cv2.mean(diff)[0] < 30 and cv2.mean(diff)[0] > 1:\n",
    "                        #print(\"diff= \" + str(cv2.mean(diff)[0]))\n",
    "                        cv2.imshow(\"face0\", gray0)\n",
    "                        cv2.imshow(\"face1\", gray1)\n",
    "                        cv2.rectangle(frame_out, (x0, y0), (x0 + w0, y0 + h0), (0, 0, 255), 2)\n",
    "                        cv2.rectangle(frame_out, (x1, y1), (x1 + w1, y1 + h1), (0, 0, 255), 2)    \n",
    "    \n",
    "    \n",
    "    ####    \n",
    "    #將找到的臉已藍框框起來\n",
    "    #將找到的路人全部用綠色框起來\n",
    "    for (x, y, w, h) in locations:\n",
    "        cv2.rectangle(frame_out, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    \n",
    "        \n",
    "    cv2.imshow(\"find_two_look_alike\", frame_out)\n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找路人只需很簡單的使用cv2.HOGDescriptor()的方法  \n",
    "找臉也只需要只用face_cascade.detectMultiScale()  \n",
    "麻煩的是找兩個相似的臉  \n",
    "如果使用cv2.matchTemplate可以將所有的臉都當成一次模板與其他臉都做一次比對  \n",
    "但光是像第1題一樣只使用一個模板去偵測的速度就已經很慢了  \n",
    "何況這邊要使用所有的臉都當一次模板      \n",
    "由於兩個臉大小不一樣故需要先做resize統一大小  \n",
    "接著用cv2.absdiff()讓每個臉對各自進行比對  \n",
    "當相異程度小於一定的值，則表示他們是一樣的臉  \n",
    "另一個麻煩的是設定face_cascade.detectMultiScale()的值  \n",
    "設定太小會找到很多不是臉的東西，設定太大則很難找到臉  \n",
    "為了多找幾個臉，這邊偏好讓他設定小一點，找錯也沒關係，目標是找到兩個相似的臉  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bboxes[max_index] = \n",
      "[500.  91.  84. 168.]\n",
      "x, y, w, h\n",
      "500.0 91.0 84.0 168.0\n",
      "bboxes[max_index] = \n",
      "[499.  92.  84. 168.]\n",
      "x, y, w, h\n",
      "499.0 92.0 84.0 168.0\n",
      "bboxes[max_index] = \n",
      "[501.  91.  84. 168.]\n",
      "x, y, w, h\n",
      "501.0 91.0 84.0 168.0\n",
      "bboxes[max_index] = \n",
      "[503.  92.  84. 168.]\n",
      "x, y, w, h\n",
      "503.0 92.0 84.0 168.0\n",
      "bboxes[max_index] = \n",
      "[332.   0.  65. 130.]\n",
      "x, y, w, h\n",
      "332.0 0.0 65.0 130.0\n",
      "bboxes[max_index] = \n",
      "[1128.  302.  113.  226.]\n",
      "x, y, w, h\n",
      "1128.0 302.0 113.0 226.0\n",
      "bboxes[max_index] = \n",
      "[1132.  303.  113.  226.]\n",
      "x, y, w, h\n",
      "1132.0 303.0 113.0 226.0\n",
      "bboxes[max_index] = \n",
      "[1135.  306.  113.  226.]\n",
      "x, y, w, h\n",
      "1135.0 306.0 113.0 226.0\n",
      "bboxes[max_index] = \n",
      "[1135.  308.  113.  226.]\n",
      "x, y, w, h\n",
      "1135.0 308.0 113.0 226.0\n",
      "bboxes[max_index] = \n",
      "[1139.  314.  113.  226.]\n",
      "x, y, w, h\n",
      "1139.0 314.0 113.0 226.0\n"
     ]
    }
   ],
   "source": [
    "#game_3 : \"find_the_fastest_character\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "scaling_factor = 1\n",
    "cap = cv2.VideoCapture(\"wiiplay.mp4\")\n",
    "frame_seq = 2480\n",
    "#face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES , frame_seq)\n",
    "status_cap, frame0 = cap.read()\n",
    "#\n",
    "#找路人\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "height, width =frame.shape[0:2]\n",
    "locations, weights = hog.detectMultiScale(frame, hitThreshold = 0.15, winStride=(1,1), groupThreshold = 1)\n",
    "\n",
    "\n",
    "#\n",
    "#抓到第一偵的人臉\n",
    "#face_rects = face_cascade.detectMultiScale(frame, scaleFactor=1.03, minNeighbors=3)\n",
    "#建立多tracker清單\n",
    "trackers = cv2.legacy.MultiTracker_create()\n",
    "#初始化tracker清單\n",
    "'''\n",
    "if len(locations) > 0:\n",
    "    x, y, w, h = locations[0]\n",
    "    print(\"----\")\n",
    "    print(x, y, w, h)\n",
    "    bbox = (x, y, w, h)\n",
    "    tracker = cv2.legacy.TrackerMIL_create()\n",
    "    status_tracker = tracker.init(frame, bbox)\n",
    "else:\n",
    "    print(\"err\")\n",
    "    exit()\n",
    "    \n",
    "'''\n",
    "#選擇初始區域\n",
    "bounding_boxes = []\n",
    "for (x,y,w,h) in locations:\n",
    "    bbox = (x, y, w, h)\n",
    "    #將抓到的每一個人臉個別建立tracker並加入多tracker清單之中\n",
    "    bounding_boxes.append(bbox)\n",
    "    tracker = cv2.legacy.TrackerMIL_create()\n",
    "    trackers.add(tracker,frame, bbox)\n",
    "\n",
    "#先在第一偵以藍色框畫出之後將要tracker的目標\n",
    "first_frame = np.copy(frame0)\n",
    "for i, new_box in enumerate(bounding_boxes):\n",
    "            x, y, w, h = [int(v) for v in new_box]\n",
    "            cv2.rectangle(first_frame, (x, y), (x+w, y+h), (255, 0, 0), 3)\n",
    "cv2.imshow(\"first frame\", first_frame)\n",
    "while True:\n",
    "    frame_seq += 1\n",
    "    if frame_seq > 2600:\n",
    "        frame_seq = 2480\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES , frame_seq)\n",
    "    status_cap, frame0 = cap.read()\n",
    "    if not status_cap:\n",
    "        break\n",
    "    frame = cv2.resize(frame0, None, fx=scaling_factor, fy=scaling_factor)\n",
    "    ###\n",
    "    #for (x,y,w,h) in face_rects:\n",
    "    #    print(\"****\")\n",
    "    #    print(x,y,w,h)\n",
    "    #print(\"----\")\n",
    "    #face_rects = face_cascade.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=3)\n",
    "    \n",
    "    \n",
    "    #持續刷新tracker \n",
    "    status_tracker, bboxes = trackers.update(frame)\n",
    "    max_displacement = 0\n",
    "    max_index = -1\n",
    "    if status_tracker:\n",
    "        for i, new_box in enumerate(bboxes):\n",
    "            x, y, w, h = [int(v) for v in new_box]\n",
    "            #將每個抓到的臉都畫出綠色框\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "            \n",
    "            #計算每一個框的位移量，找出最大，紀錄此框的index\n",
    "            displacement = (x - bounding_boxes[i][0]) ** 2 + (y - bounding_boxes[i][1]) ** 2\n",
    "            if displacement > max_displacement:\n",
    "                max_displacement = displacement\n",
    "                max_index = i\n",
    "    \n",
    "    #將找到的最大框的index\n",
    "    print(\"bboxes[max_index] = \")\n",
    "    print(bboxes[max_index])\n",
    "    x, y, w, h = bboxes[max_index]\n",
    "    print(\"x, y, w, h\")\n",
    "    print(x, y, w, h)\n",
    "    #以紅色框畫出位移量最大的物件\n",
    "    cv2.rectangle(frame, (int(x), int(y)), (int(x)+int(w), int(y)+int(h)), (0,0 , 255), 3)\n",
    "    \n",
    "    #for (x,y,w,h) in face_rects:\n",
    "    #    cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3)\n",
    "    \n",
    "    ###\n",
    "    cv2.imshow(\"find_the_fastest_character\", frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原本想說偵測行人的方法速度比較慢，享用人臉來追蹤的，但後來發現找行人的效果比較好  \n",
    "用cv2.legacy.MultiTracker_create()來建立多個Tracker的清單  \n",
    "用trackers.add(tracker,frame, bbox)將偵測到個每一個locations加入tracker  \n",
    "a)先在第一幀依照locations劃出藍色矩形 \n",
    "用trackers.update(frame)來持續追蹤tracker到的臉  \n",
    "b)接著用trackers.update(frame)回傳的bboxes畫出綠色矩形，同時計算哪個位移量最高  \n",
    "c)因為在b已經計算出bboxes上第幾個index位移量快高，故只須根據這個index畫出紅色矩形  \n",
    "同樣因為hog.detectMultiScale同個畫面每次抓地都不太一樣  \n",
    "不一定每次都能抓到右上角那個在跑的人 所以可能要多嘗試幾次  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "312 84 30 30\n"
     ]
    }
   ],
   "source": [
    "#game_4 : \"find_two_odds\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def display_flow(img, flow, stride=10):\n",
    "    for index in np.ndindex(flow[::stride, ::stride].shape[:2]):\n",
    "        pt1 = tuple(i*stride for i in index)\n",
    "        delta = flow[pt1].astype(np.int32)[::-1]\n",
    "        pt2 = tuple(pt1 + 2*delta)\n",
    "        if 2 <= cv2.norm(delta) <= 10:\n",
    "            cv2.arrowedLine(img, pt1[::-1], pt2[::-1], (255,0,0), 1, cv2.LINE_AA, 0, 0.1)\n",
    "    #norm_opt_flow = np.linalg.norm(flow, axis=2)\n",
    "    #norm_opt_flow = cv2.normalize(norm_opt_flow, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    cv2.imshow('find_two_odds', img)\n",
    "    #cv2.imshow('optical flow magnitude', norm_opt_flow)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "scaling_factor = 1\n",
    "cap = cv2.VideoCapture(\"wiiplay.mp4\")\n",
    "ini_seq = 1680\n",
    "frame_seq = ini_seq\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES , frame_seq)\n",
    "_ , frame = cap.read()\n",
    "frame0 = cv2.resize(frame, (0,0), None, 0.5, 0.5)\n",
    "prev_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "prev_frame = cv2.resize(prev_frame, (0,0), None, 0.5, 0.5)\n",
    "first_frame = True\n",
    "####face_tracker\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "#抓到第一偵的人臉\n",
    "face_rects = face_cascade.detectMultiScale(frame0, scaleFactor=1.0001, minNeighbors=3,maxSize = (50,50))\n",
    "#建立多tracker清單\n",
    "trackers = cv2.legacy.MultiTracker_create()\n",
    "#初始化tracker清單\n",
    "if len(face_rects) > 0:\n",
    "    x, y, w, h = face_rects[0]\n",
    "    print(\"----\")\n",
    "    print(x, y, w, h)\n",
    "    bbox = (x, y, w, h)\n",
    "    tracker = cv2.legacy.TrackerMIL_create()\n",
    "    status_tracker = tracker.init(frame0, bbox)\n",
    "else:\n",
    "    print(\"err\")\n",
    "    exit()\n",
    "#選擇初始區域\n",
    "bounding_boxes = []\n",
    "\n",
    "for (x,y,w,h) in face_rects:\n",
    "    bbox = (x, y, w, h)\n",
    "    #將抓到的每一個人臉個別建立tracker並加入多tracker清單之中\n",
    "    bounding_boxes.append(bbox)\n",
    "    tracker = cv2.legacy.TrackerMIL_create()\n",
    "    trackers.add(tracker,frame0, bbox)\n",
    "\n",
    "#先在第一偵以藍色框畫出之後將要tracker的目標\n",
    "first_frame_ = np.copy(frame0)\n",
    "for i, new_box in enumerate(bounding_boxes):\n",
    "            x, y, w, h = [int(v) for v in new_box]\n",
    "            cv2.rectangle(first_frame_, (x, y), (x+w, y+h), (255, 0, 0), 3)\n",
    "cv2.imshow(\"first frame\", first_frame_)\n",
    "\n",
    "####\n",
    "while True:\n",
    "    frame_seq += 1\n",
    "    if frame_seq > 1800:\n",
    "        frame_seq = ini_seq\n",
    "    status_cap, frame0 = cap.read()\n",
    "    frame = np.copy(frame0)\n",
    "    frame = cv2.resize(frame, (0,0), None, 0.5, 0.5)\n",
    "    if not status_cap:\n",
    "        break\n",
    "    ################################\n",
    "    #持續刷新tracker \n",
    "    b = 0\n",
    "    r = 0\n",
    "    \n",
    "    color = []\n",
    "    \n",
    "    status_tracker, bboxes = trackers.update(frame)\n",
    "    max_displacement = 0\n",
    "    max_index = -1\n",
    "    if status_tracker:\n",
    "        for i, new_box in enumerate(bboxes):\n",
    "            x, y, w, h = [int(v) for v in new_box]\n",
    "            #將每個抓到的臉都畫出綠色框\n",
    "            #cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "            \n",
    "            #計算每一個框的位移量，找出最大，紀錄此框的index\n",
    "            displacement = (x - bounding_boxes[i][0])\n",
    "            if displacement > 4 :#往右位移藍色框\n",
    "                #print(\"blue\"+str(displacement))\n",
    "                #cv2.rectangle(frame, (x, y), (x+w, y+h), (255,0, 0), 3)\n",
    "                color.append(1)\n",
    "                b+=1\n",
    "            elif displacement < -4 :#往左位移紅色框\n",
    "                #print(\"red\"+str(displacement))\n",
    "                #cv2.rectangle(frame, (x, y), (x+w, y+h), (0,0,255), 3)\n",
    "                \n",
    "                color.append(-1)\n",
    "                r+=1\n",
    "            else :\n",
    "                color.append(0)\n",
    "                #print(\"greeb\"+str(displacement))\n",
    "                #cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255, 0), 3)\n",
    "\n",
    "    \n",
    "    if b>r:\n",
    "        for i in range(len(color)):\n",
    "            if color[i] ==-1:\n",
    "                x, y, w, h = bboxes[i]\n",
    "                cv2.rectangle(frame, (int(x), int(y)), (int(x)+int(w), int(y)+int(h)), (0,0 ,255), 3)\n",
    "    elif b<r :\n",
    "        for i in range(len(color)):\n",
    "            if color[i] ==1:\n",
    "                x, y, w, h = bboxes[i]\n",
    "                cv2.rectangle(frame, (int(x), int(y)), (int(x)+int(w), int(y)+int(h)), (0,0 ,255), 3)\n",
    "    color.clear()\n",
    "    #######################################\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #use cv2.calcOpticalFlowPyrLK() for sparse optical flow\n",
    "    if first_frame:\n",
    "        opt_flow = cv2.calcOpticalFlowFarneback(prev_frame, gray, None, 0.5, 5, 13, 10, 5, 1.1, cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
    "        first_frame = False\n",
    "    else:\n",
    "        opt_flow = cv2.calcOpticalFlowFarneback(prev_frame, gray, opt_flow, 0.5, 5, 13, 10, 5, 1.1, cv2.OPTFLOW_USE_INITIAL_FLOW)\n",
    "    prev_frame = np.copy(gray)\n",
    "    if display_flow(frame, opt_flow):\n",
    "        break;\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "嘗試使用mp.solutions.face_detection找人臉，但不適用於wii的小人當中  \n",
    "也有想過用光流的方式找出頭往左邊側與右邊側的人，但移動量太小，光流基本上無法判斷  \n",
    "最後使用tracker的方式，第一偵先跳過第幾關的畫面，直接跳到關卡開始的時候，以這偵的圖像找人臉  \n",
    "因為需要盡可能地多抓到幾個，所以導致參數設得很低，計算量變多，偵數下降  \n",
    "但透過找到大部分的臉以後，計算每個臉的x軸位移量判斷他們正在往左看還是往右看，並統計兩者數量  \n",
    "因為只有兩個人是往不同方向看，所以就可以判斷是哪兩個人與其他人看的方向不一樣  \n",
    "最後就可以將這兩個人以紅色框起來  \n",
    "雖然有時候會抓到奇怪的框/臉，但在轉向時基本上都能抓出來。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game_5: hand gestures of Rock, Scissor, Paper\n",
    "#pip install mediapipe\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "import math\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "############################\n",
    "#計算兩點的角度\n",
    "def vector_2d_angle(v1, v2):\n",
    "    v1_x = v1[0]\n",
    "    v1_y = v1[1]\n",
    "    v2_x = v2[0]\n",
    "    v2_y = v2[1]\n",
    "    #print(v1_x ,v1_y,v2_x ,v2_y)\n",
    "    try:\n",
    "        angle_= math.degrees(math.acos((v1_x*v2_x+v1_y*v2_y)/(((v1_x**2+v1_y**2)**0.5)*((v2_x**2+v2_y**2)**0.5))))\n",
    "    except:\n",
    "        angle_ = 180\n",
    "    return angle_\n",
    "\n",
    "#根據傳來的手計算各個需要的角度\n",
    "def hand_angle(hand_):\n",
    "    angle_list = []\n",
    "    # thumb 大拇指\n",
    "    angle_ = vector_2d_angle(\n",
    "        ((int(hand_[0][0])- int(hand_[2][0])),(int(hand_[0][1])-int(hand_[2][1]))),\n",
    "        ((int(hand_[3][0])- int(hand_[4][0])),(int(hand_[3][1])- int(hand_[4][1])))\n",
    "        )\n",
    "    angle_list.append(angle_)\n",
    "    # index 食指\n",
    "    angle_ = vector_2d_angle(\n",
    "        ((int(hand_[0][0])-int(hand_[6][0])),(int(hand_[0][1])- int(hand_[6][1]))),\n",
    "        ((int(hand_[7][0])- int(hand_[8][0])),(int(hand_[7][1])- int(hand_[8][1])))\n",
    "        )\n",
    "    angle_list.append(angle_)\n",
    "    # middle 中指\n",
    "    angle_ = vector_2d_angle(\n",
    "        ((int(hand_[0][0])- int(hand_[10][0])),(int(hand_[0][1])- int(hand_[10][1]))),\n",
    "        ((int(hand_[11][0])- int(hand_[12][0])),(int(hand_[11][1])- int(hand_[12][1])))\n",
    "        )\n",
    "    angle_list.append(angle_)\n",
    "    # ring 無名指\n",
    "    angle_ = vector_2d_angle(\n",
    "        ((int(hand_[0][0])- int(hand_[14][0])),(int(hand_[0][1])- int(hand_[14][1]))),\n",
    "        ((int(hand_[15][0])- int(hand_[16][0])),(int(hand_[15][1])- int(hand_[16][1])))\n",
    "        )\n",
    "    angle_list.append(angle_)\n",
    "    # pink 小拇指\n",
    "    angle_ = vector_2d_angle(\n",
    "        ((int(hand_[0][0])- int(hand_[18][0])),(int(hand_[0][1])- int(hand_[18][1]))),\n",
    "        ((int(hand_[19][0])- int(hand_[20][0])),(int(hand_[19][1])- int(hand_[20][1])))\n",
    "        )\n",
    "    angle_list.append(angle_)\n",
    "    return angle_list\n",
    "#根據各個手指的角度，判斷目前是哪個手勢\n",
    "def hand_pos(finger_angle):\n",
    "    f1 = finger_angle[0]   # 大拇指\n",
    "    f2 = finger_angle[1]   # 食指\n",
    "    f3 = finger_angle[2]   # 中指\n",
    "    f4 = finger_angle[3]   # 無名指\n",
    "    f5 = finger_angle[4]   # 小拇指\n",
    "    #print(f1,f2,f3,f4,f5)\n",
    "    if f1>=50 and f2>=50 and f3>=50 and f4>=50 and f5>=50:\n",
    "        return 'stone'\n",
    "    elif f1>=50 and f2<50 and f3<50 and f4>=50 and f5>=50:\n",
    "        return 'scissors'\n",
    "    elif f1<50 and f2<50 and f3<50 and f4<50 and f5<50:\n",
    "        return 'paper'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "\n",
    "################################\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(\"HG.mp4\")\n",
    "frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "w = frameWidth\n",
    "h = frameHeight\n",
    "\n",
    "with mp_hands.Hands(model_complexity=0,min_detection_confidence=0.5,min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "        img2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "        results = hands.process(img2)               \n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                finger_points = []                   # 記錄手指的點\n",
    "                for i in hand_landmarks.landmark:\n",
    "                    #將這些點轉換成圖上的座標\n",
    "                    x = i.x*w\n",
    "                    y = i.y*h\n",
    "                    finger_points.append((x,y))\n",
    "                    cv2.circle(image,(int(x),int(y)), 10, (255, 0, 0), 2)\n",
    "                if finger_points:\n",
    "                    finger_angle = hand_angle(finger_points) # 計算手指角度\n",
    "                    text = hand_pos(finger_angle)            # 取得手勢所回傳的內容\n",
    "                    cv2.putText(image, text, (0,50), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 3, cv2.LINE_AA) # 印出文字\n",
    "                    for hand_landmarks in results.multi_hand_landmarks:\n",
    "                        mp_drawing.draw_landmarks(\n",
    "                        image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                \n",
    "        cv2.imshow('MediaPipe Hands', image)\n",
    "        c = cv2.waitKey(1)\n",
    "        if c == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "程式碼參考 https://steam.oxxostudio.tw/category/python/ai/ai-mediapipe-gesture.html  \n",
    "他把0~9的手勢都做出來，我看了一下把需要的手勢拿出來改一下  \n",
    "\"2\" -> 剪刀 \"0\" -> 石頭  \"5\" -> 布  \n",
    "主要的方法就是計算五隻手指與掌心的角度  \n",
    "到了一定角度代表這隻手指是捲曲狀態  \n",
    "剪刀 -> 除了食指中指以外都捲曲  \n",
    "石頭 -> 全部捲曲  \n",
    "布 -> 都沒捲曲  \n",
    "經過測試，旋轉、縮放應該可以一樣能判斷出來  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### %%writefile test\n",
    "## Final Exam\n",
    "<b>The general objective is to solve five different games.<br>\n",
    "The code for each game should be written in an individual cell.<br>\n",
    "Add comments in your code to explain your approach.<br>\n",
    "You can design your own approach, and use any method you learned in this class.</b><br>\n",
    "\n",
    "1A. Input images from video file WiiPlay.mp4 with level 15 (frame number between 4820 and 5000).<br> \n",
    "1B. (5pts) Acquire a <b>face template</b> from the first frame (frame number = 4820).<br>\n",
    "1C. (10pts) Try to detect the face the same as the template on subsequent frames, draw a <b>red</b> rectangle around the detected face, and show the output images in the <b>\"find_this_mii\"</b> window.<br><br>\n",
    "\n",
    "2A. Input images from video file WiiPlay.mp4 with level 8 (frame number between 2180 and 2380).<br>\n",
    "2B. (5pts) Detect <b>pedestrians</b> on each frame and draw a <b>green</b> rectangle around your detection.<br>\n",
    "2C. (5pts) Detect <b>faces</b> on each frame and draw a <b>blue</b> rectangle around your detection.<br>\n",
    "2D. (10pts) Try to find two faces look like each other, draw a <b>red</b> rectangle around each of the two faces, and show the output images in the <b>\"find_two_look_alike\"</b> window.<br><br>\n",
    "\n",
    "3A. Input images from video file WiiPlay.mp4 with level 9 (frame number between 2480 and 2600).<br>\n",
    "3B. (5pts) <b>Detect </b>faces(or pedestrians) on the first frame and draw a <b>blue</b> rectangle around your detection.<br>\n",
    "3C. (10pts) <b>Track </b>faces(or pedestrians) on subsequent frames and draw a <b>green</b> rectangle around your tracking.<br>\n",
    "3D. (5pts) Try to find out the fastest character, draw a <b>red</b> rectangle around the fastest character, and show the output images in the <b>\"find_the_fastest_character\"</b> window.<br><br>\n",
    "\n",
    "4A. Input images from video file WiiPlay.mp4 with level 6 (frame number between 1650 and 1800).<br>\n",
    "4B. (10pts) Compute and show <b>optical flows</b> on each frame using <b>blue</b> arrows.<br>\n",
    "4C. (5pts) Try to detect two odd character who face the opposite direction from everyone else, draw a <b>red</b> rectangle around each of the two character, and show the output images in the <b>\"find_two_odds\"</b> window.<br><br>\n",
    "\n",
    "5A. Input continuous BGR images from webcam.<br>\n",
    "5B. (5pts) Use <i>MediaPipe()</i> to detect and track one of your hands.<br>\n",
    "5C. (5pts) Obtain the positions of 21 <b>HandLandmarks</b>, draw a <b>blue</b> circle around each HandLandmark.<br>\n",
    "5D. (10pts) Design an algorithm to recognize three hand gestures of <b>Rock, Scissor, Paper</b>. Write the type of the recognized hand gesture on the upper left corner using <i>cv2.putText()</i>.<br>\n",
    "5E. In additon to translation, can your method correctly handle <b>rotated</b> (5pts bonus) and <b>scaled</b> (5pts bonus) hand gestures?<br><br>\n",
    "\n",
    "6. (5pts) Any comments regarding the final exam? Which steps you believe you have completed? Which steps bother you?<br>\n",
    "7. (5pts) Any suggestion to teaching assistants to improve this class? Any suggestion to teacher to improve this class?<br>\n",
    "8. Upload your Jupyter file (*.ipynb) with code (for 1-5) and report (for 6-7). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "6.沒甚麼意見。全部的步驟基本上都有找到方法解決，但有些不太確定是自身硬體太爛的關係所以成效不佳，速度很慢。  \n",
    "只要是用到face_cascade.detectMultiScale的方式都蠻卡的，Template也很卡  \n",
    "主要最麻煩困擾的一題應該是第4題，原本是想說去\"判斷\"每個人的臉是往左擺還是往右擺  \n",
    "想到的辦法只有1.自行訓練資料 然後再去去測 2.以上課給的人臉訓練資料，將計算每個臉的眼睛、嘴等等角度去判斷  \n",
    "但1.有點難，而且這樣還要另外上傳訓練後的model，2.則是在第4題有提到，該訓練資料不能辨識wii的小人臉  \n",
    "後來想說能不能用光流的方式去算各個臉是正要往左還是往右擺，但影片的幅度不夠，光流基本上沒有  \n",
    "最後想到的方法就只有用trackr計算抓到的每個臉的移動軌跡，將正在往左擺與正在往右擺做分類  \n",
    "最少的那個即是我們要的。  \n",
    "\n",
    "7.無。硬要說的話就是好不容易上課地點在VR教室，希望可以玩一玩VR。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
